{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DL21-fall-shw7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG1xM5jKDKAb"
      },
      "source": [
        "# Adversarial X\n",
        "\n",
        "**Разработчики: Алексей Умнов, Александр Шевченко, Ирина Сапарина**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_f6c8kGaMOR"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw7/DL21-fall-shw7.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulaAsvdTb9jU"
      },
      "source": [
        "# Load dependencies\n",
        "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw7/net_weights.pth\"\n",
        "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw7/test_array_sign.pth\"\n",
        "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw7/test_array_step.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkKJ5GKZDKBQ"
      },
      "source": [
        "# Adversarial examples\n",
        "\n",
        "В этом разделе мы будем создавать adversarial примеры для типичной архитектуры сетей. Для начала нужно сделать простую сверточную сеть для классификации (2-3 слоя) и обучить ее до нормального качества (>97%). Для экономии времени не нужно обучать ее слишком много эпох как мы это делали ранее.\n",
        "\n",
        "*Упражнение.* Можете попробовать дома обучить сеть до сходимости и сравнить, какой из вариантов более уязвим к таким атакам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SuGVnQ1DKBS"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.sampler import Sampler, BatchSampler\n",
        "from torch.nn.modules.loss import MSELoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyEW6GMyDKBX"
      },
      "source": [
        "input_size = 784\n",
        "num_classes = 10\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./MNIST/', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./MNIST/', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size,         \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp_85ryyDKBa"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    # YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7_L05jDKBe"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "        \n",
        "def train_epoch(model, optimizer, batchsize=32):\n",
        "    loss_log, acc_log = [], []\n",
        "    model.train()\n",
        "    for _, (x_batch, y_batch) in zip(trange(len(train_loader)), train_loader):\n",
        "        data = x_batch\n",
        "        target = y_batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)   \n",
        "        \n",
        "        pred = torch.max(output, 1)[1]\n",
        "        acc = torch.eq(pred, y_batch).float().mean()\n",
        "        acc_log.append(acc)\n",
        "        \n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss = loss.item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log, acc_log\n",
        "\n",
        "def test(model):\n",
        "    loss_log, acc_log = [], []\n",
        "    model.eval()\n",
        "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):  \n",
        "        data = x_batch\n",
        "        target = y_batch\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        \n",
        "        pred = torch.max(output, 1)[1]\n",
        "        acc = torch.eq(pred, y_batch).float().mean()\n",
        "        acc_log.append(acc)\n",
        "        \n",
        "        loss = loss.item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log, acc_log\n",
        "\n",
        "def plot_history(train_history, val_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    \n",
        "    points = np.array(val_history)\n",
        "    \n",
        "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.xlabel('train steps')\n",
        "    \n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def train(model, opt, n_epochs):\n",
        "    train_log, train_acc_log = [], []\n",
        "    val_log, val_acc_log = [], []\n",
        "\n",
        "    batchsize = 32\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, opt, batchsize=batchsize)\n",
        "\n",
        "        val_loss, val_acc = test(model)\n",
        "\n",
        "        train_log.extend(train_loss)\n",
        "        train_acc_log.extend(train_acc)\n",
        "\n",
        "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
        "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
        "        val_acc_log.append((steps * (epoch + 1), np.mean(val_acc)))\n",
        "\n",
        "        clear_output()\n",
        "        plot_history(train_log, val_log)    \n",
        "        plot_history(train_acc_log, val_acc_log, title='accuracy')   \n",
        "            \n",
        "    print(\"Final error: {:.2%}\".format(1 - val_acc_log[-1][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qra-zqnmDKBi"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = ConvNet()\n",
        "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "train(model, opt, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exUfkeTIDKBm"
      },
      "source": [
        "Теперь возьмем несколько изображений, которые мы будем пытаться искажать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxGzDRXIDKBn"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "inputs, labels = iter(test_loader).next()\n",
        "inputs = inputs[:4]\n",
        "labels = labels[:4]\n",
        "\n",
        "def imshow(images):\n",
        "    img = images\n",
        "    img = torchvision.utils.make_grid(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "imshow(inputs)\n",
        "print(labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbfnVmNDDKBs"
      },
      "source": [
        "Реализуйте простой способ adversarial-атаки: сделайте шаг градиентного подъема по входам (изображениям) для увеличения ошибки классификации. Подберите шаг, чтобы значения предсказания уже начинали меняться, но визуально цифра мало менялась (т.е. вы бы по-прежнему ее распознали как ту же цифру с высокой уверенностью)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4wuQCnYDKBt"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def corrupt_simple(inputs, labels, model, weight):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return corrupted_inputs\n",
        "\n",
        "corrupted_inputs = corrupt_simple(inputs, labels, model, 200)\n",
        "imshow(corrupted_inputs.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp_k0K2JDKBx"
      },
      "source": [
        "class testConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, (5, 5)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.classifier = nn.Linear(12 * 12 * 4, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        f = self.features(x.view(-1, 1, 28, 28))\n",
        "        out = self.classifier(f.view(-1, 12 * 12 * 4))\n",
        "        return F.log_softmax(out, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj1zHqe2DKB0"
      },
      "source": [
        "test_net = testConvNet()\n",
        "test_dict = torch.load('net_weights.pth')\n",
        "test_net.load_state_dict(test_dict)\n",
        "\n",
        "corrupted_inputs_test = corrupt_simple(inputs, labels, test_net, 200)\n",
        "outputs_ = test_net(corrupted_inputs_test)\n",
        "\n",
        "golden_array = torch.load('test_array_step.pth')\n",
        "assert np.allclose(outputs_.detach().numpy(), golden_array.detach().numpy(), atol=1e-4), \"Check your corrupt_simple function\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zImy7oR9DKB4"
      },
      "source": [
        "outputs = model(corrupted_inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(predicted.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRn6tA-3DKB7"
      },
      "source": [
        "Видно, что в таком подходе приходится уже сильно исказить изображение, чтобы ответы начали меняться. Если вместо градиента использовать только его знак (по каждой координате), то результаты получаются лучше. Реализуйте такой метод."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEJgPbZDKB8"
      },
      "source": [
        "def corrupt_sign(inputs, labels, model, weight):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return corrupted_inputs\n",
        "\n",
        "corrupted_inputs = corrupt_sign(inputs, labels, model, 0.2)\n",
        "imshow(corrupted_inputs.data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mq2q9xRDKCA"
      },
      "source": [
        "test_net = testConvNet()\n",
        "test_dict = torch.load('net_weights.pth')\n",
        "test_net.load_state_dict(test_dict)\n",
        "\n",
        "corrupted_inputs_test = corrupt_sign(inputs, labels, test_net, 0.2)\n",
        "outputs_ = test_net(corrupted_inputs_test)\n",
        "\n",
        "golden_array = torch.load('test_array_sign.pth')\n",
        "assert np.allclose(outputs_.detach().numpy(), golden_array.detach().numpy()), \"Check your corrupt_sign function\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE8yxO5uDKCD"
      },
      "source": [
        "outputs = model(corrupted_inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(predicted.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pkmq9hxDKCH"
      },
      "source": [
        "Теперь посмотрим как сильно меняется точность на всей выборке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRXYqYN8DKCI"
      },
      "source": [
        "def evaluate_network_attack(net, corrupt_function, weight):\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = corrupt_function(images, labels, net, weight)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        c = (predicted == labels).long().squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    print('Accuracy %d %% \\n' % (100. * sum(class_correct) / sum(class_total)))\n",
        "        \n",
        "    for i in range(10):\n",
        "        print('Accuracy of %2s : %2d %%' % (\n",
        "              i, 100. * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4EQuq0ODKCL"
      },
      "source": [
        "evaluate_network_attack(model, corrupt_simple, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6sIwBsVDKCO"
      },
      "source": [
        "evaluate_network_attack(model, corrupt_sign, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpU8isE9HeBn"
      },
      "source": [
        "# Super-resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSkfwlfWHfdz"
      },
      "source": [
        "В этой части вам предстоит реализовать простейшую архитектуру для решения задачи image super-resolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnAvLOUzHt8_"
      },
      "source": [
        "Мы будем увеличивать изображения размера (14,14) в два раза по каждому измерению. Как правило, перед подачей на вход нейросети изображение низкого разрешения увеличивают до нужного размера билинейной интерполяцией, а нейросеть улучшает результат интерпляции, не меняя пространственные размеры изображения.\n",
        "\n",
        "Реализуйте нейросеть из двух сверточных слоев (5 фильтров на каждом слое), которая будет получать на вход черно-белое изображение и выдавать на выход изображение такого же размера. Нейросеть должна предсказывать добавку, которую необходимо прибавить к полученному на вход изображению низкого качества. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djxeKDpODKCU"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size,         \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR9ZutN3Hu38"
      },
      "source": [
        "n_kernels = 5\n",
        "\n",
        "class SuperResolutionNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            #<your code>\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        return output + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EhSEyAH8jh"
      },
      "source": [
        "srcnn = SuperResolutionNetwork()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL2eJAE6DKCj"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "def low_res_and_high_res(images_batch):\n",
        "    result = images_batch.clone()\n",
        "    low_res_transform = transforms.Resize((14,14))\n",
        "    high_res_transform = transforms.Resize((28,28))\n",
        "    toTensorTransform = transforms.ToTensor()\n",
        "    toImageTransform = transforms.ToPILImage()\n",
        "    for i in range(images_batch.size()[0]):\n",
        "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
        "    return result\n",
        "\n",
        "def train_epoch(model, optimizer, batchsize=32):\n",
        "    loss_log = []\n",
        "    model.train()\n",
        "    for _, (x_batch_base, _) in zip(trange(len(train_loader)), train_loader):\n",
        "        x_batch = x_batch_base.float()\n",
        "        data = low_res_and_high_res(x_batch)\n",
        "        target = x_batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)        \n",
        "        loss = F.mse_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss = loss.data.cpu().item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log   \n",
        "\n",
        "def test(model):\n",
        "    loss_log = []\n",
        "    model.eval()\n",
        "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):    \n",
        "        x_batch = x_batch.float()\n",
        "        data = low_res_and_high_res(x_batch)\n",
        "        target = x_batch\n",
        "        output = model(data)\n",
        "        loss = F.mse_loss(output, target)        \n",
        "        loss = loss.data.cpu().item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log\n",
        "\n",
        "def plot_history(train_history, val_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    points = np.array(val_history)\n",
        "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "def train(model, opt, n_epochs):\n",
        "    train_log = []\n",
        "    val_log = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train_epoch(model, opt, batchsize=batch_size)\n",
        "        val_loss = test(model)\n",
        "        train_log.extend(train_loss)\n",
        "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
        "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
        "        clear_output()\n",
        "        plot_history(train_log, val_log)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo8OZB-pIqU-"
      },
      "source": [
        "Оптимизируйте сеть с параметрами, указанными ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXY22pH-IsMq"
      },
      "source": [
        "%%time \n",
        "\n",
        "opt = torch.optim.Adam(srcnn.parameters(), lr=0.005)\n",
        "train(srcnn, opt, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6_3zt2yIzms"
      },
      "source": [
        "Код ниже визуализирует исходные изображения (28,28) и реконструкции, полученные с помощью нейросети. Не удивляйтесь, есть качество реконструкций покажется низким, так как MSE-loss, который мы использовали при обучении, не является оптимальным для задачи super-resolution (гораздо лучше работают adversarial-сети)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuwuVvwBDKCp"
      },
      "source": [
        "test_images = test_dataset.test_data.float() / 255\n",
        "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
        "result_cnn = srcnn(test_images_blurred)\n",
        "\n",
        "examplesCount = 6\n",
        "plt.figure(figsize=[5, 10])\n",
        "for i in range(examplesCount):\n",
        "    plt.subplot(examplesCount, 3, i * 3 + 1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(test_images[i].numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.subplot(examplesCount, 3, i * 3 + 2)\n",
        "    mse = np.mean((test_images[i].numpy() - result_cnn[i].data.numpy())**2)\n",
        "    plt.title(\"CNN, MSE={:.2}\".format(mse))\n",
        "    plt.imshow(result_cnn[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.subplot(examplesCount, 3, i * 3 + 3)\n",
        "    mse = np.mean((test_images[i].numpy() - test_images_blurred[i].numpy())**2)\n",
        "    plt.title(\"LQ, MSE={:.2}\".format(mse))\n",
        "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIpybTGoDKCS"
      },
      "source": [
        "# Adversarial networks\n",
        "\n",
        "На этом семинаре мы поработаем с adversarial-архитектурами. Мы не будем обучать полноценную генеративную модель (GAN), так как это потребует много времени, а вместо этого вернемся к задаче повышения разрешения изображений и попробуем улучшить нашу модель с помощью advesarial-подхода (получится упрощенный SRGAN).\n",
        "\n",
        "Как мы обсуждали ранее, MSE хоть и является простой и удобной метрикой, она плохо отражает визуальные характеристики изображений. Поэтому мы добавим дискриминатор, который будет пытаться отличить изображения высокого качества от наших результатов, и в модели повышающей разрешение будем пытаться его обмануть.\n",
        "\n",
        "Если это записать строго, то у нас будут две сети: $D$ - дискриминатор и $E$ - сеть, повышающая разрешение, и оптимизировать мы для них будем следующие целевые функции соответсвенно:\n",
        "\n",
        "$$\n",
        "    \\min_D \\bigl[ \\mathrm{BCE}(D(E(x_l)), 0) + \\mathrm{BCE}(D(x_h), 1) \\bigr],\n",
        "$$\n",
        "\n",
        "$$\n",
        "    \\min_E \\bigl[ \\| E(x_l) - x_h \\|_2^2 - \\lambda \\cdot \\mathrm{BCE}(D(E(x_l)), 0) \\bigr],\n",
        "$$\n",
        "\n",
        "где $BCE(l, y)$ - бинарная кросс-энтропия между ответами $l$ и метками $y$, $x_l$ - изображения низкого качества, $x_h$ - изображения высокого качества.\n",
        "\n",
        "*Упражнение.* Почему в целевой функции для $E$ нет компоненты $\\mathrm{BCE}(D(x_h), 1)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O_O0mp4DKCs"
      },
      "source": [
        "Создайте простую сеть (2-3 слоя) для бинарной классификации изображений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsi6FiXoDKCt"
      },
      "source": [
        "class DiscriminatorNetwork(nn.Module):\n",
        "    \n",
        "    # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8UBPs_DKCw"
      },
      "source": [
        "srgan = SuperResolutionNetwork()\n",
        "disc = DiscriminatorNetwork()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKYtQmntDKCz"
      },
      "source": [
        "При оптимизации adversarial-архитектур возникает дополнительная сложность - сети необходимо оптимизировать поочередно. Иногда для них приходится подбирать оптимальное соотношение числа шагов, но мы ограничимся вариантом 1:1. Допишите недостающий код оптимизации ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1iR8ukDKCz"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size,         \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yh8DSOEDKC2"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "def low_res_and_high_res(images_batch):\n",
        "    result = images_batch.clone()\n",
        "    low_res_transform = transforms.Resize((14,14))\n",
        "    high_res_transform = transforms.Resize((28,28))\n",
        "    toTensorTransform = transforms.ToTensor()\n",
        "    toImageTransform = transforms.ToPILImage()\n",
        "    for i in range(images_batch.size()[0]):\n",
        "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
        "    return result\n",
        "\n",
        "\n",
        "DISC_LOSS_WEIGHT = 0.1\n",
        "\n",
        "def losses(model, disc, x_batch):\n",
        "    data = low_res_and_high_res(x_batch)\n",
        "    target = x_batch\n",
        "    output = model(data)\n",
        "\n",
        "    # YOUR CODE\n",
        "    \n",
        "    return disc_loss, model_loss\n",
        "    \n",
        "\n",
        "def train_epoch(model, disc, m_opt, d_opt, batchsize=32):\n",
        "    d_loss_log = []\n",
        "    m_loss_log = []\n",
        "    model.train()\n",
        "    for batch_num, (x_batch_base, _) in zip(trange(len(train_loader)), train_loader):\n",
        "        x_batch = x_batch_base.float()\n",
        "        d_loss, m_loss = losses(model, disc, x_batch)\n",
        "            \n",
        "        # YOUR CODE \n",
        "            \n",
        "        d_loss_log.append(d_loss.item())\n",
        "        m_loss_log.append(m_loss.item())\n",
        "    return d_loss_log, m_loss_log \n",
        "\n",
        "def test(model, disc):\n",
        "    d_loss_log = []\n",
        "    m_loss_log = []\n",
        "    model.eval()\n",
        "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):\n",
        "        d_loss, m_loss = losses(model, disc, x_batch)\n",
        "        d_loss_log.append(d_loss.item())\n",
        "        m_loss_log.append(m_loss.item())\n",
        "    return d_loss_log, m_loss_log \n",
        "\n",
        "def plot_history(train_history, val_history, title='loss'):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_history[0], label='train', zorder=1)\n",
        "    points = np.array(val_history)\n",
        "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.title('Discriminator loss')\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_history[1], label='train', zorder=1)\n",
        "    points = np.array(val_history)\n",
        "    plt.scatter(points[:, 0], points[:, 2], marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "def train(model, disc, m_opt, d_opt, n_epochs):\n",
        "    train_log = [[], []]\n",
        "    val_log = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train_epoch(model, disc, m_opt, d_opt, batchsize=batch_size)\n",
        "        val_loss = test(model, disc)\n",
        "        train_log[0].extend(train_loss[0])\n",
        "        train_log[1].extend(train_loss[1])\n",
        "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
        "        val_log.append((steps * (epoch + 1), np.mean(val_loss[0]), np.mean(val_loss[1])))\n",
        "        clear_output()\n",
        "        plot_history(train_log, val_log)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cudCeYwDKC5"
      },
      "source": [
        "Теперь запустим оптимизацию. Большая проблема при работе с adversarial-моделями - в том, что по графикам оптимизации мало чего понятно. То есть по ним можно увидеть какое-то совсем плохое поведение и, возможно, найти ошибки в коде, но вот понять, дообучилась ли сеть, или ее еще стоит пообучать, часто нельзя. Обычно все метрики просто колеблются вокруг константы, но при этом сеть обучается (по очереди происходит небольшое улучшение дискриминатора, а потом оно тут же убирается основной сетью).\n",
        "\n",
        "Обучите сеть на 2-3 эпохах и добейтесь, чтобы влияние adversarial-потерь было заметно (на примерах ниже). Для этого потребуется, чтобы качество дискриминатора не ушло совсем в 0. Возможно, придется немного поиграться с параметрами.\n",
        "\n",
        "Потом дома можно оставить обучение на 5-10 эпох и увидеть изменения в качестве.\n",
        "\n",
        "Также обратите внимание, что MSE для adversarial-архитектуры выходит хуже, чем обычной. Но мы так и планировали сделать - ведь MSE плохо оценивает визуальное качество."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2vAcF9jDKC6"
      },
      "source": [
        "%%time\n",
        "\n",
        "m_opt = torch.optim.Adam(srgan.parameters(), lr=0.005)\n",
        "d_opt = torch.optim.Adam(disc.parameters(), lr=0.005)\n",
        "train(srgan, disc, m_opt, d_opt, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27k20czhDKC9"
      },
      "source": [
        "test_images = test_dataset.test_data.float() / 255\n",
        "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
        "result_cnn = srcnn(test_images_blurred)\n",
        "result_gan = srgan(test_images_blurred)\n",
        "\n",
        "examplesCount = 6\n",
        "rows, cols = examplesCount, 4\n",
        "plt.figure(figsize=[7, 10])\n",
        "for i in range(examplesCount):\n",
        "    plt.subplot(rows, cols, i * cols + 1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(test_images[i].numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.subplot(rows, cols, i * cols + 2)\n",
        "    mse = np.mean((test_images[i].numpy() - result_gan[i].data.numpy())**2)\n",
        "    plt.title(\"GAN+MSE, MSE={:.2f}\".format(mse))\n",
        "    plt.imshow(result_gan[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.subplot(rows, cols, i * cols + 3)\n",
        "    mse = np.mean((test_images[i].numpy() - result_cnn[i].data.numpy())**2)\n",
        "    plt.title(\"MSE, MSE={:.2f}\".format(mse))\n",
        "    plt.imshow(result_cnn[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.subplot(rows, cols, i * cols + 4)\n",
        "    mse = np.mean((test_images[i].numpy() - test_images_blurred[i].numpy())**2)\n",
        "    plt.title(\"LQ, MSE={:.2f}\".format(mse))\n",
        "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWMd21TEDKDB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
