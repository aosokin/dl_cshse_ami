{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные сети в задачах компьютерного зрения\n",
    "\n",
    "**Разработчик: Артем Бабенко**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом семинаре необходимо будет (1) реализовать простейшую metric learning архитектуру на основе сиамской нейросети с Contrastive Loss и использовать ее для поиска похожих изображений (2) реализовать fully convolutional сеть для задачи image super-resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning (0.7 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import Sampler, BatchSampler\n",
    "from torch.nn.modules.loss import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо реализовать вычисление Contrastive Loss - одну из самых популярных функций потерь для metric learning. Contrastive Loss получает на вход пару векторов $x_i$ и $x_j$ (признаковые описания объектов $i$ и $j$, полученные нейросетью) и метку $y_{ij}$, причем $y_{ij} = 0$, если объекты \"похожи\" (принадлежат одному классу), и $y_{ij} = 1$, если объекты \"различны\" (принадлежат различным классам). Формально определим Contrastive Loss следующим образом:\n",
    "\n",
    "$$\n",
    "L(x_i, x_j, y_{ij}) = (1 - y_{ij})\\|x_i - x_j\\|^2 + y_{ij}max(0, m - \\|x_i - x_j\\|^2)\n",
    "$$\n",
    "\n",
    "где $m$ - гиперпараметр (его можно взять равным единице).\n",
    "\n",
    "Вместо того, чтобы формировать обучающее множество из всевозможных пар, можно поступить проще: будем пропускать батч из $N$ обучаюших изображений через сеть (тем самым получая соответствующие векторы $x$), а значение лосса вычислять как среднее значение функции $L$ на всех парах в этом батче. Тогда в обучении на каждом батче участвует $\\frac{N(N-1)}{2}$ пар, что существенно ускоряет сходимость на практике. Реализуйте предложенный вариант Contrastive Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах metric learning, как правило, необходимо, чтобы количества \"положительных\" и \"отрицательных\" пар в обучении отличалось несильно. Поэтому в случае большого количества классов случайное формирование батчей неэффективно - в таком случае количество \"положительных\" пар очень мало. Поэтому будем формировать обучающие батчи размера $N$ следующим образом: будем брать $\\frac{N}{2}$ элементов из некоторого класса (они между собой будут формировать \"положительные пары\"), а оставшиеся $\\frac{N}{2}$ элементов будем брать случайно. Таким образом мы гарантируем, что в каждом обучающем батче будет достаточно \"положительных\" пар.\n",
    "\n",
    "Реализуйте предложенную логику в рамках Pytorch, реализовав собственный BatchSampler. Ваш самплер должен формировать каждый батч размера $N$ следующим образом: $\\frac{N}{2}$ объектов извлекаются из некоторого случайного класса, оставшиеся $\\frac{N}{2}$ объектов извлекаются случайно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContrastiveSampler(BatchSampler):\n",
    "    def __init__(self, batch_size, num_classes, labels):\n",
    "        self.num_classes = num_classes\n",
    "        self.imgs_per_class = labels.size()[0] // num_classes\n",
    "        #<your code>\n",
    "\n",
    "    def __iter__(self):\n",
    "        num_yielded = 0\n",
    "        while num_yielded < (self.num_classes * self.imgs_per_class):\n",
    "            batch = []\n",
    "            #<your code>\n",
    "            num_yielded += self.batch_size\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будем работать с небольшими изображениями одежды из датасета Fashion-MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = dsets.FashionMNIST(root='.', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "test_dataset = dsets.FashionMNIST(root='.', \n",
    "                                  train=False, \n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_sampler=ContrastiveSampler(batch_size=batch_size, num_classes=num_classes, labels=train_dataset.train_labels), \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_sampler=ContrastiveSampler(batch_size=batch_size, num_classes=num_classes, labels=test_dataset.test_labels), \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте сеть несложной архитектуры, содержащую три сверточных слоя из 20 фильтров с макс-пулингом, а также два полносвязных слоя из 128 нейронов. Выход последнего слоя будет подаваться на вход Contrastive Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n",
    "\n",
    "class ContrastiveNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            #<your code>\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)        \n",
    "        loss = contrastive_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch_num, (data, target) in enumerate(test_loader):    \n",
    "        output = model(data)\n",
    "        loss = contrastive_loss(output, target)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)    \n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs))\n",
    "        train_loss = train_epoch(model, opt)\n",
    "        val_loss = test(model)\n",
    "        train_log.extend(train_loss)\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ContrastiveNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите сеть с параметрами, указанными ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "train(model, opt, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлеките векторные описания тестовых изображений (a.k.a эмбеддинги). У вас должно получиться 10000 128-мерных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = #<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже демонстрирует поисковую выдачу для трех изображений-запросов. Выдача формируется на основе близости эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryCount = 3\n",
    "queries = embeddings[:queryCount,:].data.numpy()\n",
    "database = embeddings[queryCount:,:].data.numpy()\n",
    "plt.figure(figsize=[15, 4.5])\n",
    "for i in range(queryCount):\n",
    "    results = np.argsort(np.sum((database-queries[i,:])**2, axis=1))[:10]\n",
    "    plt.subplot(queryCount, 11, i * 11 + 1)\n",
    "    plt.title(\"Query: %i\" % i)\n",
    "    plt.imshow(test_dataset.test_data[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    for k in range(10):\n",
    "        plt.subplot(queryCount, 11, i * 11 + k + 2)\n",
    "        plt.imshow(test_dataset.test_data[results[k]+queryCount].numpy().reshape([28, 28]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам предстоит реализовать простейшую архитектуру для решения задачи image super-resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,         \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем увеличивать изображения размера (14,14) в два раза по каждому измерению. Как правило, перед подачей на вход нейросети изображение низкого разрешения увеличивают до нужного размера билинейной интерполяцией, а нейросеть улучшает результат интерпляции, не меняя пространственные размеры изображения.\n",
    "\n",
    "Реализуйте нейросеть из трех сверточных слоев (10 фильтров на каждом слое), которая будет получать на вход черно-белое изображение и выдавать на выход изображение такого же размера. Нейросеть должна предсказывать добавку, которую необходимо прибавить к полученному на вход изображению низкого качества. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SuperResolutionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            #<your code>\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SuperResolutionNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def low_res_and_high_res(images_batch):\n",
    "    result = images_batch.clone()\n",
    "    low_res_transform = transforms.Resize((14,14))\n",
    "    high_res_transform = transforms.Resize((28,28))\n",
    "    toTensorTransform = transforms.ToTensor()\n",
    "    toImageTransform = transforms.ToPILImage()\n",
    "    for i in range(images_batch.size()[0]):\n",
    "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
    "    return result\n",
    "\n",
    "def train_epoch(model, optimizer, batchsize=32):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for batch_num, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        data = low_res_and_high_res(x_batch.float())\n",
    "        target = x_batch\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)        \n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):    \n",
    "        data = low_res_and_high_res(x_batch.float())\n",
    "        target = x_batch\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)        \n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs))\n",
    "        train_loss = train_epoch(model, opt, batchsize=batch_size)\n",
    "        val_loss = test(model)\n",
    "        train_log.extend(train_loss)\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизируйте сеть с параметрами, указанными ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.05)\n",
    "train(model, opt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_dataset.test_data.float() / 255\n",
    "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
    "result_cnn = model(test_images_blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже визуализирует исходные изображения (28,28) и реконструкции, полученные с помощью нейросети.\n",
    "Не удивляйтесь, есть качество реконструкций покажется низким, скоро вы узнаете, что MSE-loss, который мы использовали при обучении, не является оптимальным для задачи super-resolution (гораздо лучше работают adversarial-сети, про которые вам расскажут через пару недель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examplesCount = 6\n",
    "plt.figure(figsize=[10, 10])\n",
    "for i in range(examplesCount):\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 1)\n",
    "    plt.title(\"Original: %i\" % i)\n",
    "    plt.imshow(test_dataset.test_data[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 2)\n",
    "    plt.title(\"Upscaled-CNN: %i\" % i)\n",
    "    plt.imshow(np.clip(result_cnn[i].data.numpy().reshape([28, 28]), 0, 1), cmap='gray')\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 3)\n",
    "    plt.title(\"Upscaled initial %i\" % i)\n",
    "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
